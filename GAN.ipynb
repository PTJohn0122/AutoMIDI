{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from midi2img import midi2image\n",
    "from img2midi import image2midi\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from skimage import img_as_ubyte\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert midi to image\n",
    "isExist = os.path.exists(\"../res/midi2img\")\n",
    "if not isExist:\n",
    "    os.makedirs(\"../res/midi2img\")\n",
    "\n",
    "os.chdir(\"../res/midi2img\")\n",
    "midi_file = glob.glob(\"../../data/mozart/*.mid\")\n",
    "\n",
    "for midi in midi_file:\n",
    "    try:\n",
    "        midi = midi2image(midi)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess the images\n",
    "\n",
    "def input_prep_fn(x):\n",
    "    \n",
    "    out = tf.image.resize(x, size = [106,106]) / 255.0\n",
    "    out = np.array(out)\n",
    "    out[out > 0] = 1\n",
    "    return 2 * out - 1\n",
    "\n",
    "image_file = glob.glob(\"midi2img/*.png\")\n",
    "image_file = image_file\n",
    "images = []\n",
    "for i in image_file:\n",
    "    image = tf.keras.utils.load_img(i, color_mode = \"grayscale\")\n",
    "    image = tf.keras.utils.img_to_array(image)\n",
    "    images.append(image) \n",
    "images = np.array(images)\n",
    "images = input_prep_fn(images)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(np.array(images[i]), cmap='gray')\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def define_discriminator(in_shape = (106,106,1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(128, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    n_nodes = 256 * 53 * 53\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(BatchNormalization()) ##\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((53, 53, 256)))\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(1,1), padding='same', use_bias=False)) #\n",
    "    model.add(LeakyReLU(alpha=0.2)) #\n",
    "    model.add(Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', use_bias=False))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(1, (7,7) , padding='same',activation = 'tanh', use_bias=False))\n",
    "    return model\n",
    "\n",
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = g_model.predict(x_input, verbose=0)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=51, n_batch=10, file_dir = \"model_test\"):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "\n",
    "    d_loss_list = []\n",
    "    g_loss_list = [] \n",
    "    for i in range(n_epochs):\n",
    "        print(\"Epoch %d\" %(i+1))\n",
    "        for j in range(bat_per_epo):\n",
    "            \n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "\n",
    "            #d_model.trainable = True\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "\n",
    "            #d_model.trainable = False\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            print('>%d/%d, d=%.3f, g=%.3f' % (j+1, bat_per_epo, d_loss, g_loss))\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            summarize_performance(file_dir, i, g_model, d_model, dataset, latent_dim)\n",
    "            #clear_output()\n",
    "            \n",
    "        d_loss_list.append(d_loss)\n",
    "        g_loss_list.append(g_loss)\n",
    "    \n",
    "    return d_loss_list, g_loss_list\n",
    "\n",
    "def summarize_performance(file_dir, epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
    "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "    filename = 'generator_model_%03d.h5' % (epoch + 1)\n",
    "\n",
    "    isExist = os.path.exists(file_dir)\n",
    "    if not isExist:\n",
    "        os.makedirs(file_dir)\n",
    "    g_model.save(file_dir + \"/\" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize the model\n",
    "\n",
    "latent_dim = 100\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "print(images.shape)\n",
    "print(np.unique(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss, g_loss = train(g_model, d_model, gan_model, images, latent_dim, n_epochs = 400, n_batch=50, file_dir = \"model_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax1.plot(d_loss, c = 'b')\n",
    "ax1.set_title(\"Discriminator Loss\")\n",
    "\n",
    "ax2.plot(g_loss, c = 'r')\n",
    "ax2.set_title(\"Generator Loss\")\n",
    "fig.supxlabel('Epoch')\n",
    "plt.show()\n",
    "fig.savefig(\"res/model_out/\" + 'loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "latent_dim = 100\n",
    "sim_input = generate_latent_points(latent_dim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = [\"010\", \"020\", \"030\", \"040\", \"050\", \"060\", \"070\", \"080\", \"090\"]\n",
    "#fig, axs = plt.subplots(len(model_index),figsize=(20, 3.5))\n",
    "for index, value in enumerate(model_index):\n",
    "    model = keras.models.load_model('res/model_out/generator_model_' + value +'.h5', compile=False)\n",
    "    X = model.predict(sim_input, verbose=0)\n",
    "    X = np.squeeze(X)\n",
    "    plt.subplot(3,3,index+1)\n",
    "    #plt.subplots(1)\n",
    "    plt.title(\"Epoch \"+value)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X, cmap='gray')\n",
    "    plt.savefig(\"res/model_out/\" + 'train_examine.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate music\n",
    "model = keras.models.load_model('res/model_out/generator_model_400.h5', compile=False)\n",
    "\n",
    "latent_dim = 100\n",
    "latent_points = generate_latent_points(latent_dim, 1)\n",
    "\n",
    "out = model.predict(latent_points)\n",
    "out = np.squeeze(out)\n",
    "\n",
    "img = img_as_ubyte(out)\n",
    "plt.imshow(img, cmap='gray')\n",
    "new_image = Image.fromarray(img,'L')\n",
    "new_image = new_image.save('res/model_out/composition.png')\n",
    "\n",
    "image2midi(\"composition.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post process stage to Jazzify the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
